
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Privacy-preserving machine learning: Methods, challenges and directions &#8212; Paper Digest</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=d69f3b5a" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'paper/xu2021privacy';</script>
    <link rel="icon" href="https://hsiangjenli.github.io/static/image/ico.svg"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="On hyperparameter optimization of machine learning algorithms: Theory and practice" href="yang2020hyperparameter.html" />
    <link rel="prev" title="Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges" href="rodriguez2023survey.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Paper Digest</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Table of Contents:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="rigaki2023survey.html">A survey of privacy attacks in machine learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="rodriguez2023survey.html">Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Privacy-preserving machine learning: Methods, challenges and directions</a></li>
<li class="toctree-l1"><a class="reference internal" href="yang2020hyperparameter.html">On hyperparameter optimization of machine learning algorithms: Theory and practice</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ðŸš€ PPML</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../resource/ppml.html">Open Source Repositories for PPML</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../resource/notebook/nb_tenseal.html">OpenMined/TenSEAL</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Privacy-preserving machine learning: Methods, challenges and directions</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/paper/xu2021privacy.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Privacy-preserving machine learning: Methods, challenges and directions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#before-starting">Before starting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-terms">Key Terms</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contributions-xu2021privacy">Contributions <span class="xref cite">xu2021privacy</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#phases-of-ml-pipeline">Phases of ML Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-data-preparation-data-perspective">Privacy Preserving Data Preparation (Data Perspective)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-model-training-computational-perspective">Privacy Preserving Model Training (Computational Perspective)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-model-serving-model-perspective">Privacy Preserving Model Serving (Model Perspective)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-guarantee">Privacy Guarantee</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="privacy-preserving-machine-learning-methods-challenges-and-directions">
<h1>Privacy-preserving machine learning: Methods, challenges and directions<a class="headerlink" href="#privacy-preserving-machine-learning-methods-challenges-and-directions" title="Link to this heading">#</a></h1>
<div class="admonition note">
    <p class="admonition-title">Note</p>
    <p>Hey guys, this is my personal reading note. I am not sure there might be some mistakes in my understanding. Please feel free to correct me (<a class="reference external" href="mailto:hsiangjenli&#37;&#52;&#48;gmail&#46;com">hsiangjenli<span>&#64;</span>gmail<span>&#46;</span>com</a>) if you find any. Thanks!</p>
</div><ul class="simple">
<li><p>Publish Year : <span id="id1"><a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">2021</a></span></p></li>
<li><p>Authors : <span id="id2"><a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">Xu, Baracaldo, and Joshi</a></span></p></li>
</ul>
<section id="before-starting">
<h2>Before starting<a class="headerlink" href="#before-starting" title="Link to this heading">#</a></h2>
<p>Before starting to read the paper, the basic concepts you need to know are as follows:</p>
<ul class="simple">
<li><p>Entire ML pipeline process</p></li>
<li><p>The participants in the ML pipeline</p></li>
</ul>
<section id="key-terms">
<h3>Key Terms<a class="headerlink" href="#key-terms" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Privacy-preserving machine learning (PPML)</p></li>
<li><p>Complete Model <span class="math notranslate nohighlight">\(\rightarrow\)</span> Train on <strong>single</strong> machine</p></li>
<li><p>Global Model <span class="math notranslate nohighlight">\(\rightarrow\)</span> Train on <strong>multiple</strong> machines</p></li>
<li><p>Data Producer (DP)</p></li>
<li><p>Model Consumer (MC)</p></li>
<li><p>Computational Facility (CF)</p></li>
<li><p>Confidential-level privacy</p></li>
<li><p>Homomorphic encryption (HE)</p></li>
<li><p>Functional encryption (FE)</p></li>
<li><p>Differential privacy</p></li>
<li><p>Multi-party computation (MPC)</p></li>
<li><p>Secure multi-party computation (SMPC)</p></li>
<li><p>Garbled circuit</p></li>
<li><p>Oblivious transfer</p></li>
</ol>
</section>
<section id="contributions-xu2021privacy">
<h3>Contributions <span id="id3">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span><a class="headerlink" href="#contributions-xu2021privacy" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Existing privacy preserving approaches</p></li>
<li><p>Proposed an evaluation framework for PPML, which decomposes privacy-preserving features into distinct Phase, Guarantee, and Utility aspects (PGU).</p></li>
</ol>
<ul>
<li><p>Phase : Represents the use of privacy-preserving techniques at different stages in the ML pipeline</p></li>
<li><p>Guarantee : In specific scenarios, privacy-preserving techniques provide certain levels of privacy protection</p></li>
<li><p>Utility : The impact of privacy-preserving techniques on the modelâ€™s performance</p>
<blockquote>
<div></div></blockquote>
</li>
</ul>
</section>
</section>
<section id="phases-of-ml-pipeline">
<h2>Phases of ML Pipeline<a class="headerlink" href="#phases-of-ml-pipeline" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>The techniques that can be applied to training phase, it also can be applied to the serving phase. <span id="id4">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></p></li>
<li><p>However, the techniques that can be applied to the serving phase, it may not be applied to the training phase. <span id="id5">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></p></li>
</ul>
</div></blockquote>
<figure class="align-default" id="id58">
<img alt="../_images/image.png" src="../_images/image.png" />
<figcaption>
<p><span class="caption-text">This figure is taken from the paper <span id="id6">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></span><a class="headerlink" href="#id58" title="Link to this image">#</a></p>
</figcaption>
</figure>
<section id="privacy-preserving-data-preparation-data-perspective">
<h3>Privacy Preserving Data Preparation (Data Perspective)<a class="headerlink" href="#privacy-preserving-data-preparation-data-perspective" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Traditional anonymization mechanism</strong> : Remove the identifier information before training</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k\)</span>-anonymity <span id="id7">[<a class="reference internal" href="#id37" title="Latanya Sweeney. K-anonymity: a model for protecting privacy. International journal of uncertainty, fuzziness and knowledge-based systems, 10(05):557â€“570, 2002.">2</a>]</span></p></li>
<li><p><span class="math notranslate nohighlight">\(l\)</span>-diversity <span id="id8">[<a class="reference internal" href="#id38" title="Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and Muthuramakrishnan Venkitasubramaniam. L-diversity: privacy beyond k-anonymity. Acm transactions on knowledge discovery from data (tkdd), 1(1):3â€“es, 2007.">3</a>]</span></p></li>
<li><p><span class="math notranslate nohighlight">\(t\)</span>-closeness <span id="id9">[<a class="reference internal" href="#id39" title="Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian. T-closeness: privacy beyond k-anonymity and l-diversity. In 2007 IEEE 23rd international conference on data engineering, 106â€“115. IEEE, 2006.">4</a>]</span></p></li>
</ul>
</li>
<li><p><strong>Surrogate dataset</strong></p>
<ul class="simple">
<li><p>Grouping the anonymized data <span id="id10">[<a class="reference internal" href="#id40" title="Mengwei Yang, Linqi Song, Jie Xu, Congduan Li, and Guozhen Tan. The tradeoff between privacy and accuracy in anomaly detection using federated xgboost. arXiv preprint arXiv:1907.07157, 2019.">5</a>]</span></p></li>
<li><p>Abstracting the data by sketch techniques <span id="id11">[<a class="reference internal" href="#id44" title="Tian Li, Zaoxing Liu, Vyas Sekar, and Virginia Smith. Privacy for free: communication-efficient learning with differential privacy using sketches. arXiv preprint arXiv:1911.00972, 2019.">6</a>, <a class="reference internal" href="#id45" title="Farzin Haddadpour, Belhal Karimi, Ping Li, and Xiaoyun Li. Fedsketch: communication-efficient and private federated learning via sketching. arXiv preprint arXiv:2008.04975, 2020.">7</a>]</span></p></li>
</ul>
</li>
<li><p><strong>Differential privacy mechanism</strong> <span id="id12">[<a class="reference internal" href="#id41" title="Cynthia Dwork. Differential privacy: a survey of results. In International conference on theory and applications of models of computation, 1â€“19. Springer, 2008.">8</a>, <a class="reference internal" href="#id42" title="Cynthia Dwork, Guy N Rothblum, and Salil Vadhan. Boosting and differential privacy. In 2010 IEEE 51st annual symposium on foundations of computer science, 51â€“60. IEEE, 2010.">9</a>, <a class="reference internal" href="#id43" title="Cynthia Dwork, Aaron Roth, and others. The algorithmic foundations of differential privacy. Foundations and TrendsÂ® in Theoretical Computer Science, 9(3â€“4):211â€“407, 2014.">10</a>]</span> : Add noise to the data to avoid privacy leakage</p>
<ul class="simple">
<li><p>Inference or de-anonymization attacks <span id="id13">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span> : Like <span id="id14">[<a class="reference internal" href="#id46" title="Gilbert Wondracek, Thorsten Holz, Engin Kirda, and Christopher Kruegel. A practical attack to de-anonymize social network users. In 2010 ieee symposium on security and privacy, 223â€“238. IEEE, 2010.">11</a>, <a class="reference internal" href="#id47" title="Md Atiqur Rahman, Tanzila Rahman, Robert LaganiÃ¨re, Noman Mohammed, and Yang Wang. Membership inference attack against differentially private deep learning model. Trans. Data Priv., 11(1):61â€“79, 2018.">12</a>, <a class="reference internal" href="#id48" title="Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy (SP), 3â€“18. IEEE, 2017.">13</a>, <a class="reference internal" href="#id49" title="Jianwei Qian, Xiang-Yang Li, Chunhong Zhang, and Linlin Chen. De-anonymizing social networks and inferring private attributes using knowledge graphs. In IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications, 1â€“9. IEEE, 2016.">14</a>]</span></p></li>
</ul>
</li>
<li><p><strong>Encrypted data</strong></p>
<ul class="simple">
<li><p>Confidential-level privacy</p></li>
</ul>
</li>
</ol>
</section>
<section id="privacy-preserving-model-training-computational-perspective">
<h3>Privacy Preserving Model Training (Computational Perspective)<a class="headerlink" href="#privacy-preserving-model-training-computational-perspective" title="Link to this heading">#</a></h3>
<p>Supporting computation on encrypted data <span id="id15">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span>. Typically, encryption techniques involve two main steps: encoding and decoding <span id="id16">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span>.</p>
<ul class="simple">
<li><p>Encoding <span class="math notranslate nohighlight">\(\rightarrow\)</span> Transform floating-point values into integers</p></li>
<li><p>Decoding <span class="math notranslate nohighlight">\(\rightarrow\)</span> Recover the floating-point values from trained model or crypto-based training results</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>Homomorphic encryption</strong> :</p>
<ul class="simple">
<li><p>BGV scheme <span id="id17">[<a class="reference internal" href="#id53" title="Masahiro Yagisawa. Fully homomorphic encryption without bootstrapping. Cryptology ePrint Archive, 2015.">15</a>]</span></p></li>
<li><p>CKKS <span id="id18">[<a class="reference internal" href="#id50" title="Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. Homomorphic encryption for arithmetic of approximate numbers. In Advances in Cryptologyâ€“ASIACRYPT 2017: 23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part I 23, 409â€“437. Springer, 2017.">16</a>]</span> : Supports approximate arithmetic computation</p></li>
</ul>
</li>
<li><p><strong>Functional encryption</strong> :</p>
<ul class="simple">
<li><p>Multi-party functional encryption <span id="id19">[<a class="reference internal" href="#id51" title="Michel Abdalla, Florian Bourse, Angelo De Caro, and David Pointcheval. Simple functional encryption schemes for inner products. In IACR International Workshop on Public Key Cryptography, 733â€“751. Springer, 2015.">17</a>, <a class="reference internal" href="#id52" title="Michel Abdalla, Dario Catalano, Dario Fiore, Romain Gay, and Bogdan Ursu. Multi-input functional encryption for inner products: function-hiding realizations and constructions without pairings. In Advances in Cryptologyâ€“CRYPTO 2018: 38th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 19â€“23, 2018, Proceedings, Part I 38, 597â€“627. Springer, 2018.">18</a>]</span></p></li>
</ul>
</li>
</ol>
</section>
<section id="privacy-preserving-model-serving-model-perspective">
<h3>Privacy Preserving Model Serving (Model Perspective)<a class="headerlink" href="#privacy-preserving-model-serving-model-perspective" title="Link to this heading">#</a></h3>
<p>Include model deployment and inference <span id="id20">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></p>
<ol class="arabic simple">
<li><p>Private aggregation of teacher ensembles (PATE)</p></li>
<li><p>Model transform</p></li>
<li><p>Model compression</p></li>
</ol>
</section>
</section>
<section id="privacy-guarantee">
<h2>Privacy Guarantee<a class="headerlink" href="#privacy-guarantee" title="Link to this heading">#</a></h2>
<ol class="arabic">
<li><p>Object-Oriented Privacy Guarantee</p>
<ul>
<li><p><strong>Data</strong> oriented privacy guarantee : Prevent the leakage of data, but it will sacrifice of the data utility <span id="id21">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></p>
<blockquote>
<div><ul class="simple">
<li><p><strong>Anonymization mechanism</strong> needs to aggregate and remove proper feature values. Simultaneously, certain values of quasi-identifier features are erased altogether</p></li>
<li><p><strong>Differential privacy</strong> requires the addition of a noise budget to the data sample.</p></li>
<li><p><strong>Encrypted data</strong> may ensure the datasetâ€™s confidentiality, it brings extra processing burden to the subsequent machine learning training.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>Model</strong> oriented privacy guarantee : Prevent adversaries from extracting private information through repeated model queries <span id="id22">[<a class="reference internal" href="#id36" title="Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. arXiv preprint arXiv:2108.04417, 2021.">1</a>]</span></p>
<blockquote>
<div><ul>
<li><p>Perturb the trained model</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>DP-SGD</strong> <span id="id23">[<a class="reference internal" href="#id54" title="Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, 308â€“318. 2016.">19</a>]</span> : Adding noise into the clipped gradients to achieve a differentially private model</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Regulate the model access times and patterns</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</li>
<li><p>Pipeline-Oriented Privacy Guarantee</p></li>
</ol>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id24">
<div role="list" class="citation-list">
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>,<a role="doc-backlink" href="#id4">4</a>,<a role="doc-backlink" href="#id5">5</a>,<a role="doc-backlink" href="#id6">6</a>,<a role="doc-backlink" href="#id13">7</a>,<a role="doc-backlink" href="#id15">8</a>,<a role="doc-backlink" href="#id16">9</a>,<a role="doc-backlink" href="#id20">10</a>,<a role="doc-backlink" href="#id21">11</a>,<a role="doc-backlink" href="#id22">12</a>)</span>
<p>Runhua Xu, Nathalie Baracaldo, and James Joshi. Privacy-preserving machine learning: methods, challenges and directions. <em>arXiv preprint arXiv:2108.04417</em>, 2021.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">2</a><span class="fn-bracket">]</span></span>
<p>Latanya Sweeney. K-anonymity: a model for protecting privacy. <em>International journal of uncertainty, fuzziness and knowledge-based systems</em>, 10(05):557â€“570, 2002.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">3</a><span class="fn-bracket">]</span></span>
<p>Ashwin Machanavajjhala, Daniel Kifer, Johannes Gehrke, and Muthuramakrishnan Venkitasubramaniam. L-diversity: privacy beyond k-anonymity. <em>Acm transactions on knowledge discovery from data (tkdd)</em>, 1(1):3â€“es, 2007.</p>
</div>
<div class="citation" id="id39" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">4</a><span class="fn-bracket">]</span></span>
<p>Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian. T-closeness: privacy beyond k-anonymity and l-diversity. In <em>2007 IEEE 23rd international conference on data engineering</em>, 106â€“115. IEEE, 2006.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id10">5</a><span class="fn-bracket">]</span></span>
<p>Mengwei Yang, Linqi Song, Jie Xu, Congduan Li, and Guozhen Tan. The tradeoff between privacy and accuracy in anomaly detection using federated xgboost. <em>arXiv preprint arXiv:1907.07157</em>, 2019.</p>
</div>
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">6</a><span class="fn-bracket">]</span></span>
<p>Tian Li, Zaoxing Liu, Vyas Sekar, and Virginia Smith. Privacy for free: communication-efficient learning with differential privacy using sketches. <em>arXiv preprint arXiv:1911.00972</em>, 2019.</p>
</div>
<div class="citation" id="id45" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id11">7</a><span class="fn-bracket">]</span></span>
<p>Farzin Haddadpour, Belhal Karimi, Ping Li, and Xiaoyun Li. Fedsketch: communication-efficient and private federated learning via sketching. <em>arXiv preprint arXiv:2008.04975</em>, 2020.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">8</a><span class="fn-bracket">]</span></span>
<p>Cynthia Dwork. Differential privacy: a survey of results. In <em>International conference on theory and applications of models of computation</em>, 1â€“19. Springer, 2008.</p>
</div>
<div class="citation" id="id42" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">9</a><span class="fn-bracket">]</span></span>
<p>Cynthia Dwork, GuyÂ N Rothblum, and Salil Vadhan. Boosting and differential privacy. In <em>2010 IEEE 51st annual symposium on foundations of computer science</em>, 51â€“60. IEEE, 2010.</p>
</div>
<div class="citation" id="id43" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">10</a><span class="fn-bracket">]</span></span>
<p>Cynthia Dwork, Aaron Roth, and others. The algorithmic foundations of differential privacy. <em>Foundations and TrendsÂ® in Theoretical Computer Science</em>, 9(3â€“4):211â€“407, 2014.</p>
</div>
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">11</a><span class="fn-bracket">]</span></span>
<p>Gilbert Wondracek, Thorsten Holz, Engin Kirda, and Christopher Kruegel. A practical attack to de-anonymize social network users. In <em>2010 ieee symposium on security and privacy</em>, 223â€“238. IEEE, 2010.</p>
</div>
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">12</a><span class="fn-bracket">]</span></span>
<p>MdÂ Atiqur Rahman, Tanzila Rahman, Robert LaganiÃ¨re, Noman Mohammed, and Yang Wang. Membership inference attack against differentially private deep learning model. <em>Trans. Data Priv.</em>, 11(1):61â€“79, 2018.</p>
</div>
<div class="citation" id="id48" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">13</a><span class="fn-bracket">]</span></span>
<p>Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against machine learning models. In <em>2017 IEEE symposium on security and privacy (SP)</em>, 3â€“18. IEEE, 2017.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">14</a><span class="fn-bracket">]</span></span>
<p>Jianwei Qian, Xiang-Yang Li, Chunhong Zhang, and Linlin Chen. De-anonymizing social networks and inferring private attributes using knowledge graphs. In <em>IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications</em>, 1â€“9. IEEE, 2016.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">15</a><span class="fn-bracket">]</span></span>
<p>Masahiro Yagisawa. Fully homomorphic encryption without bootstrapping. <em>Cryptology ePrint Archive</em>, 2015.</p>
</div>
<div class="citation" id="id50" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">16</a><span class="fn-bracket">]</span></span>
<p>JungÂ Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. Homomorphic encryption for arithmetic of approximate numbers. In <em>Advances in Cryptologyâ€“ASIACRYPT 2017: 23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part I 23</em>, 409â€“437. Springer, 2017.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">17</a><span class="fn-bracket">]</span></span>
<p>Michel Abdalla, Florian Bourse, Angelo DeÂ Caro, and David Pointcheval. Simple functional encryption schemes for inner products. In <em>IACR International Workshop on Public Key Cryptography</em>, 733â€“751. Springer, 2015.</p>
</div>
<div class="citation" id="id52" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">18</a><span class="fn-bracket">]</span></span>
<p>Michel Abdalla, Dario Catalano, Dario Fiore, Romain Gay, and Bogdan Ursu. Multi-input functional encryption for inner products: function-hiding realizations and constructions without pairings. In <em>Advances in Cryptologyâ€“CRYPTO 2018: 38th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 19â€“23, 2018, Proceedings, Part I 38</em>, 597â€“627. Springer, 2018.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id23">19</a><span class="fn-bracket">]</span></span>
<p>Martin Abadi, Andy Chu, Ian Goodfellow, HÂ Brendan McMahan, Ilya Mironov, Kunal Talwar, and LiÂ Zhang. Deep learning with differential privacy. In <em>Proceedings of the 2016 ACM SIGSAC conference on computer and communications security</em>, 308â€“318. 2016.</p>
</div>
</div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="rodriguez2023survey.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges</p>
      </div>
    </a>
    <a class="right-next"
       href="yang2020hyperparameter.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">On hyperparameter optimization of machine learning algorithms: Theory and practice</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#before-starting">Before starting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-terms">Key Terms</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contributions-xu2021privacy">Contributions <span class="xref cite">xu2021privacy</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#phases-of-ml-pipeline">Phases of ML Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-data-preparation-data-perspective">Privacy Preserving Data Preparation (Data Perspective)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-model-training-computational-perspective">Privacy Preserving Model Training (Computational Perspective)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-preserving-model-serving-model-perspective">Privacy Preserving Model Serving (Model Perspective)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#privacy-guarantee">Privacy Guarantee</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Hsiang-Jen Li
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2024, Hsiang-Jen Li.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>